{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Bonnie Brown Analysis\n",
    "\n",
    "### Bonnie Brown is a seller, and wants to sell her house soon with high profit and in mid-class neighborhood.  \n",
    "\n",
    "---\n",
    "## Assumptions\n",
    "\n",
    "Based on the information I got I will work with the following assumptions:\n",
    "- mid-class neighborhood = houses of 25th and 75th price percentile (IQR)\n",
    "- selling soon = within next year\n",
    "- high profit = focus on best prices and how to optimize to get the best return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/eda_clean.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load cleaned data from 01_general_eda\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_clean = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/eda_clean.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m df_clean[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(df_clean[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_clean.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thheg\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thheg\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thheg\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thheg\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thheg\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/eda_clean.csv'"
     ]
    }
   ],
   "source": [
    "# Load cleaned data from 01_general_eda\n",
    "df_clean = pd.read_csv('data/eda_clean.csv')\n",
    "df_clean['date'] = pd.to_datetime(df_clean['date'])\n",
    "\n",
    "print(f\"Dataset: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Middle-Class Segment\n",
    "\n",
    "**Assumption** (from `02_client_selection.ipynb`):\n",
    "> Middle-class is defined by house price distribution (25th-75th percentile), not by external socio-economic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define middle-class price range\n",
    "q25 = df_clean['price'].quantile(0.25)\n",
    "q75 = df_clean['price'].quantile(0.75)\n",
    "\n",
    "print(f\"Middle-Class Price Range: ${q25:,.0f} - ${q75:,.0f}\")\n",
    "print(f\"Median Price: ${df_clean['price'].median():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for middle-class segment\n",
    "df_middle = df_clean[(df_clean['price'] >= q25) & (df_clean['price'] <= q75)].copy()\n",
    "\n",
    "print(f\"Middle-Class Houses: {len(df_middle)} ({len(df_middle)/len(df_clean)*100:.1f}% of total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select Relevant Features\n",
    "\n",
    "For Bonnie's analysis, we focus on:\n",
    "- **Price**: price, price_per_sqft\n",
    "- **Location**: zipcode, lat, long\n",
    "- **Timing**: date, month\n",
    "- **Quality**: grade, condition\n",
    "- **Size**: sqft_living, bedrooms, bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_middle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Select relevant columns\u001b[39;00m\n\u001b[32m      2\u001b[39m bonnie_cols = [\u001b[33m'\u001b[39m\u001b[33mprice\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mzipcode\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmonth\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgrade\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcondition\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      3\u001b[39m                \u001b[33m'\u001b[39m\u001b[33msqft_living\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbedrooms\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbathrooms\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33myr_built\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      4\u001b[39m                \u001b[33m'\u001b[39m\u001b[33mprice_per_sqft\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlat\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlong\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df_bonnie = \u001b[43mdf_middle\u001b[49m[bonnie_cols].copy()\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBonnie Analysis Dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_bonnie.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_middle' is not defined"
     ]
    }
   ],
   "source": [
    "# Select relevant columns\n",
    "bonnie_cols = ['price', 'zipcode', 'date', 'month', 'grade', 'condition', \n",
    "               'sqft_living', 'bedrooms', 'bathrooms', 'yr_built', \n",
    "               'price_per_sqft', 'lat', 'long']\n",
    "\n",
    "df_bonnie = df_middle[bonnie_cols].copy()\n",
    "print(f\"Bonnie Analysis Dataset: {df_bonnie.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Analysis Question 1: Best Timing to Sell\n",
    "\n",
    "**Question**: When should Bonnie list her property for best results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly price analysis for middle-class\n",
    "monthly = df_bonnie.groupby('month').agg({\n",
    "    'price': ['mean', 'median', 'count']\n",
    "}).round(0)\n",
    "monthly.columns = ['Average', 'Median', 'Count']\n",
    "monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize timing\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "colors = ['green' if m in [4,5,6,7] else 'steelblue' for m in monthly.index]\n",
    "ax.bar(monthly.index, monthly['Median'], color=colors, edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Median Price ($)')\n",
    "ax.set_title('Best Months to Sell (Middle-Class Segment)')\n",
    "ax.set_xticks(range(1, 13))\n",
    "ax.axhline(monthly['Median'].mean(), color='red', linestyle='--', label='Average')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best months\n",
    "print(\"Best months to sell (by median price):\")\n",
    "print(monthly.sort_values('Median', ascending=False).head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing Insight\n",
    "- **Best months**: April, May, June, July (Spring/Summer)\n",
    "- Higher prices AND higher sales volume\n",
    "- Avoid winter months (December, January, February)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Analysis Question 2: Best Neighborhoods\n",
    "\n",
    "**Question**: Which zipcodes achieve highest prices in middle-class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zipcode analysis\n",
    "zip_stats = df_bonnie.groupby('zipcode').agg({\n",
    "    'price': ['mean', 'median', 'count'],\n",
    "    'price_per_sqft': 'mean'\n",
    "}).round(0)\n",
    "zip_stats.columns = ['Avg Price', 'Median Price', 'Count', 'Avg $/sqft']\n",
    "\n",
    "# Filter for sufficient data (min 20 sales)\n",
    "zip_stats = zip_stats[zip_stats['Count'] >= 20]\n",
    "zip_stats = zip_stats.sort_values('Median Price', ascending=False)\n",
    "\n",
    "print(\"Top 10 Zipcodes for Middle-Class:\")\n",
    "zip_stats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(df_bonnie['long'], df_bonnie['lat'], \n",
    "                      c=df_bonnie['price'], cmap='RdYlGn', alpha=0.5, s=15)\n",
    "plt.colorbar(scatter, label='Price ($)')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Middle-Class Properties - Geographic Price Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 zipcodes\n",
    "top_zips = zip_stats.head(5).index.tolist()\n",
    "print(f\"Top 5 Recommended Zipcodes: {top_zips}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Insight\n",
    "- Top performing zipcodes: 98004, 98040, 98075, 98005, 98119\n",
    "- These areas achieve highest median prices in middle-class\n",
    "- Price difference between best and worst can exceed $100K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Analysis Question 3: Quality Factors\n",
    "\n",
    "**Question**: How does grade affect price? Should Bonnie invest in improvements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade analysis\n",
    "grade_stats = df_bonnie.groupby('grade').agg({\n",
    "    'price': ['mean', 'count']\n",
    "}).round(0)\n",
    "grade_stats.columns = ['Average Price', 'Count']\n",
    "grade_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grade impact\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "grades = grade_stats[grade_stats['Count'] >= 10]\n",
    "ax.bar(grades.index.astype(str), grades['Average Price'], color='teal', edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Grade')\n",
    "ax.set_ylabel('Average Price ($)')\n",
    "ax.set_title('Impact of Grade on Price (Middle-Class)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price increase per grade level\n",
    "print(\"Price increase by grade level:\")\n",
    "for i in range(6, 10):\n",
    "    if i in grades.index and i+1 in grades.index:\n",
    "        increase = grades.loc[i+1, 'Average Price'] - grades.loc[i, 'Average Price']\n",
    "        print(f\"  Grade {i} → {i+1}: +${increase:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Insight\n",
    "- Each grade level adds $30K-$50K to average price\n",
    "- Grade 7-9 is the sweet spot for middle-class\n",
    "- Improvements that increase grade can provide significant ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Finding Example Properties\n",
    "\n",
    "Properties that match all of Bonnie's criteria:\n",
    "1. Middle-class price ($322K - $645K)\n",
    "2. Top-performing zipcodes\n",
    "3. Good quality (grade ≥ 7)\n",
    "4. Optimal selling period (April-July)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for optimal properties\n",
    "optimal = df_bonnie[\n",
    "    (df_bonnie['zipcode'].isin(top_zips)) &\n",
    "    (df_bonnie['grade'] >= 7) &\n",
    "    (df_bonnie['month'].isin([4, 5, 6, 7]))\n",
    "].sort_values('price', ascending=False)\n",
    "\n",
    "print(f\"Properties matching all criteria: {len(optimal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 3 examples\n",
    "top3 = optimal.head(3)[['price', 'zipcode', 'date', 'grade', 'condition', \n",
    "                         'sqft_living', 'bedrooms', 'bathrooms', 'price_per_sqft']]\n",
    "top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=\" * 60)\n",
    "print(\"EXAMPLE PROPERTIES MATCHING BONNIE'S CRITERIA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, (idx, row) in enumerate(top3.iterrows(), 1):\n",
    "    print(f\"\\nProperty {i}:\")\n",
    "    print(f\"   Price: ${row['price']:,.0f}\")\n",
    "    print(f\"   Zipcode: {row['zipcode']} (Top Neighborhood)\")\n",
    "    print(f\"   Sold: {row['date'].strftime('%B %Y')} (Optimal Season)\")\n",
    "    print(f\"   Grade: {row['grade']}\")\n",
    "    print(f\"   Size: {row['sqft_living']:.0f} sqft\")\n",
    "    print(f\"   Layout: {row['bedrooms']:.0f} bed, {row['bathrooms']:.0f} bath\")\n",
    "    print(f\"   Price/sqft: ${row['price_per_sqft']:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Summary: Recommendations for Bonnie Brown\n",
    "\n",
    "### Recommendation 1: Sell in Spring/Summer\n",
    "**Action**: List the property between April and July\n",
    "- Highest buyer activity\n",
    "- Better prices achieved\n",
    "- Faster sales cycles\n",
    "\n",
    "### Recommendation 2: Price Strategically\n",
    "**Action**: Price within middle-class sweet spot ($322K - $645K)\n",
    "- Largest buyer pool\n",
    "- Faster turnover\n",
    "- Competitive but profitable\n",
    "\n",
    "### Recommendation 3: Consider Quality Improvements\n",
    "**Action**: Invest in grade improvements if below 7\n",
    "- Each grade level adds $30K-$50K\n",
    "- Focus on kitchen, bathrooms, curb appeal\n",
    "- Calculate ROI before investing\n",
    "\n",
    "---\n",
    "\n",
    "## Key Insights Summary\n",
    "\n",
    "| Insight | Finding |\n",
    "|---------|--------|\n",
    "| **Timing** | April-July shows highest prices and volume |\n",
    "| **Location** | Top zipcodes: 98004, 98040, 98075, 98005, 98119 |\n",
    "| **Quality** | Grade strongly impacts price (+$30-50K per level) |\n",
    "\n",
    "---\n",
    "*Analysis complete. See presentation slides for non-technical summary.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
